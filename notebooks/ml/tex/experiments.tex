\section{Experiments}

The following experiments refer to 3-fold cross-validation over \emph{linearly} and \emph{nonlinearly} separable generated datasets of size 100, so the reported results are to considered as a mean over the 3 folds.

\subsection{Support Vector Classifier}

Below experiments are about the SVC for which I tested different values for the regularization hyperparameter $C$, i.e., from \emph{soft} to \emph{hard margin}, and in case of nonlinearly separable data also different \emph{kernel functions} mentioned above.

\subsubsection{Hinge loss}

\input{experiments/primal_svc_hinge}

\input{experiments/linear_dual_svc}

\input{experiments/linear_lagrangian_dual_svc}

\input{experiments/nonlinear_dual_svc}

\input{experiments/nonlinear_lagrangian_dual_svc}

\subsubsection{Squared Hinge loss}

\input{experiments/primal_svc_squared_hinge}

\subsection{Support Vector Regression}

Below experiments are about the SVR for which I tested different values for regularization hyperparameter $C$, i.e., from \emph{soft} to \emph{hard margin}, the $\epsilon$ penalty value and in case of nonlinearly separable data also different \emph{kernel functions} mentioned above.

\subsubsection{Epsilon-insensitive loss}

\input{experiments/primal_svr_eps}

\input{experiments/linear_dual_svr}

\input{experiments/linear_lagrangian_dual_svr}

\input{experiments/nonlinear_dual_svr}

\input{experiments/nonlinear_lagrangian_dual_svr}

\subsubsection{Squared Epsilon-insensitive loss}

\input{experiments/primal_svr_squared_eps}

